{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b889ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Any\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37e982e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_745_124, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>friend_uid</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>93464</td><td>114312</td></tr><tr><td>93464</td><td>103690</td></tr><tr><td>93464</td><td>108045</td></tr><tr><td>93464</td><td>116128</td></tr><tr><td>93464</td><td>94113</td></tr><tr><td>93464</td><td>101668</td></tr><tr><td>93464</td><td>118820</td></tr><tr><td>93464</td><td>93617</td></tr><tr><td>93464</td><td>97587</td></tr><tr><td>93464</td><td>101941</td></tr><tr><td>93464</td><td>104574</td></tr><tr><td>93464</td><td>104636</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>96484</td><td>17519</td></tr><tr><td>89317</td><td>17519</td></tr><tr><td>40932</td><td>17519</td></tr><tr><td>29417</td><td>17519</td></tr><tr><td>48879</td><td>17519</td></tr><tr><td>22513</td><td>17519</td></tr><tr><td>109044</td><td>17519</td></tr><tr><td>41972</td><td>17519</td></tr><tr><td>47606</td><td>17519</td></tr><tr><td>93433</td><td>17519</td></tr><tr><td>105725</td><td>17519</td></tr><tr><td>88318</td><td>17519</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_745_124, 2)\n",
       "┌────────┬────────────┐\n",
       "│ uid    ┆ friend_uid │\n",
       "│ ---    ┆ ---        │\n",
       "│ i64    ┆ i64        │\n",
       "╞════════╪════════════╡\n",
       "│ 93464  ┆ 114312     │\n",
       "│ 93464  ┆ 103690     │\n",
       "│ 93464  ┆ 108045     │\n",
       "│ 93464  ┆ 116128     │\n",
       "│ …      ┆ …          │\n",
       "│ 47606  ┆ 17519      │\n",
       "│ 93433  ┆ 17519      │\n",
       "│ 105725 ┆ 17519      │\n",
       "│ 88318  ┆ 17519      │\n",
       "└────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_parquet('train.parquet')\n",
    "# датафрейм с обратными ребрами\n",
    "data_rev = (\n",
    "    data\n",
    "    .rename({'uid': 'friend_uid', 'friend_uid': 'uid'})\n",
    "    .select('uid', 'friend_uid')\n",
    ")\n",
    "\n",
    "# соединим все в один граф\n",
    "data = pl.concat([data, data_rev])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f643e51",
   "metadata": {},
   "source": [
    "Данные состоят из двух колонок:\n",
    "\n",
    "- `uid` – идентификатор пользователя\n",
    "- `friend_uid` – идентификатор друга этого пользователя\n",
    "\n",
    "Нашей задачей будет порекомендовать возможных друзей, для оценки вашего решения будет использоваться метрика Recall@10, равная проценту верно угаданных друзей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a44c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "SUBMISSION_PATH = 'submission.parquet'\n",
    "\n",
    "\n",
    "def user_intersection(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: relevant items\n",
    "    :param y_rec: recommended items\n",
    "    :param k: number of top recommended items\n",
    "    :return: number of items in intersection of y_rel and y_rec (truncated to top-K)\n",
    "    \"\"\"\n",
    "    return len(set(y_rec[:k]).intersection(set(y_rel)))\n",
    "\n",
    "\n",
    "def user_recall(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    :param y_rel: relevant items\n",
    "    :param y_rec: recommended items\n",
    "    :param k: number of top recommended items\n",
    "    :return: percentage of found relevant items through recommendations\n",
    "    \"\"\"\n",
    "    return user_intersection(y_rel, y_rec, k) / min(k, len(set(y_rel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aee09d",
   "metadata": {},
   "source": [
    "## Валидация\n",
    "\n",
    "Так как у нас нет временной последовательности и рекомендации друзей не так сильно зависят от временной составляющей, в качестве можно использовать случайно выбранные ребра в графе (при этом для каждого пользователя будет равная пропорция друзей в валидации, которую можно достичь с помощью stratify параметра)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c251a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем генератор случайных чисел\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b93e044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_166_881, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>friend_uid</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>62053</td><td>63575</td></tr><tr><td>31895</td><td>59356</td></tr><tr><td>97127</td><td>32271</td></tr><tr><td>89</td><td>11703</td></tr><tr><td>105178</td><td>47188</td></tr><tr><td>116127</td><td>52662</td></tr><tr><td>33824</td><td>15235</td></tr><tr><td>23690</td><td>103992</td></tr><tr><td>94660</td><td>45709</td></tr><tr><td>20872</td><td>60890</td></tr><tr><td>16860</td><td>107284</td></tr><tr><td>72933</td><td>24768</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>75573</td><td>85971</td></tr><tr><td>89685</td><td>35585</td></tr><tr><td>62183</td><td>105868</td></tr><tr><td>32336</td><td>44964</td></tr><tr><td>50410</td><td>92648</td></tr><tr><td>70625</td><td>16115</td></tr><tr><td>114497</td><td>88075</td></tr><tr><td>6338</td><td>75957</td></tr><tr><td>33790</td><td>82938</td></tr><tr><td>102133</td><td>62986</td></tr><tr><td>46217</td><td>78893</td></tr><tr><td>7857</td><td>101269</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_166_881, 2)\n",
       "┌────────┬────────────┐\n",
       "│ uid    ┆ friend_uid │\n",
       "│ ---    ┆ ---        │\n",
       "│ i64    ┆ i64        │\n",
       "╞════════╪════════════╡\n",
       "│ 62053  ┆ 63575      │\n",
       "│ 31895  ┆ 59356      │\n",
       "│ 97127  ┆ 32271      │\n",
       "│ 89     ┆ 11703      │\n",
       "│ …      ┆ …          │\n",
       "│ 33790  ┆ 82938      │\n",
       "│ 102133 ┆ 62986      │\n",
       "│ 46217  ┆ 78893      │\n",
       "│ 7857   ┆ 101269     │\n",
       "└────────┴────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отфильтруем тех пользователей, у которых только один друг :(\n",
    "# для того, чтобы в тренировочной выборке и валидации было хотя бы по одному другу\n",
    "friends_count = data.groupby('uid').count()\n",
    "filtered_uid = set(friends_count.filter(pl.col('count') > 1)['uid'].to_list())\n",
    "\n",
    "data_filtered = data.filter(pl.col('uid').is_in(filtered_uid))\n",
    "\n",
    "# случайно выбираем ребра для валидационной выборки\n",
    "train_df, test_df = train_test_split(\n",
    "    data_filtered.filter(pl.col('uid').is_in(filtered_uid)),\n",
    "    stratify=data_filtered['uid'],\n",
    "    test_size=0.1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c087e4d",
   "metadata": {},
   "source": [
    "## Бейзлайн (Random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3991b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "среднее число uid в user_history: 36\n"
     ]
    }
   ],
   "source": [
    "grouped_df = (\n",
    "    test_df\n",
    "    .groupby('uid')\n",
    "    .agg(pl.col('friend_uid').alias('y_rel'))\n",
    "    .join(\n",
    "        train_df\n",
    "        .groupby('uid')\n",
    "        .agg(pl.col('friend_uid').alias('user_history')),\n",
    "        'uid',\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "median_seq_len = int(grouped_df['user_history'].apply(len).median())\n",
    "print(f\"среднее число uid в user_history: {median_seq_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e628fb9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_users = train_df['uid'].max() + 1\n",
    "\n",
    "# количество друзей у каждого пользователя\n",
    "friends_count = np.zeros(n_users)\n",
    "for uid, count in Counter(train_df['uid']).items():\n",
    "    friends_count[uid] = count\n",
    "    \n",
    "friends_count /= sum(friends_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d342b007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 92562/92562 [00:04<00:00, 20068.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 = 0.0003110784946203369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recall_list = []\n",
    "recs = np.random.choice(n_users, size=(n_users, TOP_K + median_seq_len), p=friends_count)\n",
    "\n",
    "for user_id, y_rel, user_history in tqdm(grouped_df.rows()):\n",
    "    y_rec = [uid for uid in recs[user_id] if uid not in user_history]\n",
    "    recall_list.append(user_recall(y_rel, y_rec))\n",
    "    \n",
    "print(f'Recall@{TOP_K} = {np.mean(recall_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe750b0a",
   "metadata": {},
   "source": [
    "## Построим рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43934001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем вероятности уже по всем имеющимся данным\n",
    "n_users = data['uid'].max() + 1\n",
    "\n",
    "# количество друзей у каждого пользователя\n",
    "friends_count = np.zeros(n_users)\n",
    "for uid, count in Counter(data['uid']).items():\n",
    "    friends_count[uid] = count\n",
    "    \n",
    "friends_count /= sum(friends_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f64050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 85483/85483 [00:04<00:00, 18203.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (85_483, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>y_recs</th></tr><tr><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>0</td><td>[75174, 40482, … 107746]</td></tr><tr><td>1</td><td>[27663, 82181, … 37095]</td></tr><tr><td>3</td><td>[105454, 12906, … 43868]</td></tr><tr><td>4</td><td>[2627, 60169, … 108457]</td></tr><tr><td>5</td><td>[29164, 53357, … 33803]</td></tr><tr><td>6</td><td>[62015, 44506, … 3835]</td></tr><tr><td>7</td><td>[74067, 79534, … 53438]</td></tr><tr><td>8</td><td>[75913, 31803, … 32356]</td></tr><tr><td>9</td><td>[26079, 73565, … 111629]</td></tr><tr><td>10</td><td>[46650, 34491, … 116342]</td></tr><tr><td>11</td><td>[39738, 69724, … 78448]</td></tr><tr><td>13</td><td>[12205, 20978, … 117256]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>118445</td><td>[116847, 54517, … 1498]</td></tr><tr><td>118449</td><td>[114302, 88814, … 67228]</td></tr><tr><td>118563</td><td>[105582, 86380, … 25311]</td></tr><tr><td>118723</td><td>[64342, 111709, … 30420]</td></tr><tr><td>118725</td><td>[65160, 92357, … 101930]</td></tr><tr><td>119033</td><td>[85811, 41364, … 72538]</td></tr><tr><td>119155</td><td>[87355, 116208, … 93918]</td></tr><tr><td>119383</td><td>[74151, 73700, … 39997]</td></tr><tr><td>119425</td><td>[45097, 13946, … 66505]</td></tr><tr><td>119457</td><td>[48927, 100539, … 86384]</td></tr><tr><td>119486</td><td>[108964, 115849, … 6044]</td></tr><tr><td>119517</td><td>[102088, 54681, … 98159]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (85_483, 2)\n",
       "┌─────────┬──────────────────────────┐\n",
       "│ user_id ┆ y_recs                   │\n",
       "│ ---     ┆ ---                      │\n",
       "│ i64     ┆ list[i64]                │\n",
       "╞═════════╪══════════════════════════╡\n",
       "│ 0       ┆ [75174, 40482, … 107746] │\n",
       "│ 1       ┆ [27663, 82181, … 37095]  │\n",
       "│ 3       ┆ [105454, 12906, … 43868] │\n",
       "│ 4       ┆ [2627, 60169, … 108457]  │\n",
       "│ …       ┆ …                        │\n",
       "│ 119425  ┆ [45097, 13946, … 66505]  │\n",
       "│ 119457  ┆ [48927, 100539, … 86384] │\n",
       "│ 119486  ┆ [108964, 115849, … 6044] │\n",
       "│ 119517  ┆ [102088, 54681, … 98159] │\n",
       "└─────────┴──────────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pl.read_parquet('sample_submission.parquet')\n",
    "\n",
    "grouped_df = (\n",
    "    sample_submission.select('uid')\n",
    "    .join(\n",
    "        train_df\n",
    "        .groupby('uid')\n",
    "        .agg(pl.col('friend_uid').alias('user_history')),\n",
    "        'uid',\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "submission = []\n",
    "recs = np.random.choice(n_users, size=(n_users, TOP_K + median_seq_len), p=friends_count)\n",
    "\n",
    "for user_id, user_history in tqdm(grouped_df.rows()):\n",
    "    user_history = [] if user_history is None else user_history\n",
    "    \n",
    "    y_rec = [uid for uid in recs[user_id] if uid not in user_history]\n",
    "    submission.append((user_id, y_rec))\n",
    "    \n",
    "submission = pl.DataFrame(submission, schema=['user_id', 'y_recs'])\n",
    "submission.write_parquet('submission.parquet')\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7defebb-b18b-4747-8ec1-fb88bea4af3e",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c93ca1ea",
   "metadata": {},
   "source": [
    "Для установки torch-geometric пришлось ломать текущие зависимости в pyproject, устанавливал примерно так\n",
    "!pip install torch==2.2.*\n",
    "!pip install numpy==1.24.3\n",
    "!pip install --force-reinstall --no-cache-dir pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cu121.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53b5b006",
   "metadata": {},
   "source": [
    "Сначала решил попробовать простой вариант через представление юзера как мешка его друзей и затем поиска ближайших к нему по косиносному расстоянию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "12dca8db-97ac-4157-aaa1-4b9754b0a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_parquet('train.parquet')\n",
    "\n",
    "friends_count = data['uid'].value_counts().reset_index()\n",
    "friends_count.columns = ['uid', 'count']\n",
    "filtered_uid = friends_count[friends_count['count'] > 1]['uid']\n",
    "data_filtered = data[data['uid'].isin(filtered_uid)]\n",
    "\n",
    "unique_uids = pd.concat([data_filtered['uid'], data_filtered['friend_uid']]).unique()\n",
    "uid_to_index = {uid: idx for idx, uid in enumerate(unique_uids)}\n",
    "index_to_uid = {idx: uid for idx, uid in enumerate(unique_uids)}\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    data_filtered,\n",
    "    stratify=data_filtered['uid'],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df['uid'] = train_df['uid'].map(uid_to_index)\n",
    "train_df['friend_uid'] = train_df['friend_uid'].map(uid_to_index)\n",
    "\n",
    "test_df['uid'] = test_df['uid'].map(uid_to_index)\n",
    "test_df['friend_uid'] = test_df['friend_uid'].map(uid_to_index)\n",
    "\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "values = []\n",
    "\n",
    "for uid, friend_uid in train_df[['uid', 'friend_uid']].values:\n",
    "    rows.append(uid)\n",
    "    cols.append(friend_uid)\n",
    "    values.append(1)\n",
    "    \n",
    "num_users = len(unique_uids)\n",
    "sparse_data = sp.csr_matrix((values, (rows, cols)), shape=(num_users, num_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb7b858d-fcdf-4cc6-87dc-74220b4744b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106092/106092 [01:07<00:00, 1564.66it/s]\n"
     ]
    }
   ],
   "source": [
    "user_similarity = cosine_similarity(sparse_data, dense_output=False)\n",
    "\n",
    "def generate_recommendations_sparse(user_similarity, user_to_friends, top_k=10):\n",
    "    recommendations = {}\n",
    "    for user in tqdm(range(user_similarity.shape[0]), total=user_similarity.shape[0]):\n",
    "        similarities = user_similarity[user].toarray().flatten()\n",
    "        friends = user_to_friends.get(user, set())\n",
    "        candidate_users = np.argpartition(-similarities, top_k)[:top_k]\n",
    "        candidate_users = candidate_users[np.argsort(-similarities[candidate_users])]\n",
    "        candidate_users = [uid for uid in candidate_users if uid != user and uid not in friends][:top_k]\n",
    "        recommendations[user] = candidate_users\n",
    "    return recommendations\n",
    "\n",
    "user_to_friends = {uid: set(group['friend_uid']) for uid, group in train_df.groupby('uid')}\n",
    "recommendations = generate_recommendations_sparse(user_similarity, user_to_friends, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4678e622-3187-487c-8bb5-cb0a78d9e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@20 = 0.1100\n"
     ]
    }
   ],
   "source": [
    "def user_recall(y_rel, y_rec, k=10):\n",
    "    return len(set(y_rec[:k]).intersection(set(y_rel))) / min(k, len(set(y_rel)))\n",
    "\n",
    "recall_scores = []\n",
    "test_true_friends = {user: set(group['friend_uid']) for user, group in test_df.groupby('uid')}\n",
    "\n",
    "for user_id in test_true_friends:\n",
    "    if user_id in recommendations:\n",
    "        y_true = list(test_true_friends[user_id])\n",
    "        y_pred = recommendations[user_id]\n",
    "        recall_scores.append(user_recall(y_true, y_pred, k=20))\n",
    "\n",
    "mean_recall_at_20 = np.mean(recall_scores)\n",
    "print(f'Recall@20 = {mean_recall_at_10:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e11874e5",
   "metadata": {},
   "source": [
    "затем попробовал для пользователя получить эмбеддинг с помощью node2vec и искать ближайших к нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bbfda1a1-950b-406d-99b6-5db92514dd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from typing import List, Any\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid, MovieLens\n",
    "from torch_geometric.nn import Node2Vec, SAGEConv, LightGCN, to_hetero\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.utils import degree\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "data = pd.read_parquet('train.parquet')\n",
    "\n",
    "friends_count = data['uid'].value_counts().reset_index()\n",
    "friends_count.columns = ['uid', 'count']\n",
    "\n",
    "filtered_uid = friends_count[friends_count['count'] > 1]['uid']\n",
    "\n",
    "data_filtered = data[(data['uid'].isin(filtered_uid))]\n",
    "\n",
    "unique_uids = pd.concat([data_filtered['uid'], data_filtered['friend_uid']]).unique()\n",
    "uid_to_index = {uid: idx for idx, uid in enumerate(unique_uids)}\n",
    "index_to_uid = {idx: uid for idx, uid in enumerate(unique_uids)}\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    data_filtered,\n",
    "    stratify=data_filtered['uid'],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df['uid'] = train_df['uid'].map(uid_to_index)\n",
    "train_df['friend_uid'] = train_df['friend_uid'].map(uid_to_index)\n",
    "\n",
    "test_df['uid'] = test_df['uid'].map(uid_to_index)\n",
    "test_df['friend_uid'] = test_df['friend_uid'].map(uid_to_index)\n",
    "\n",
    "train_edges = torch.tensor([[uid, friend_uid] for uid, friend_uid in train_df.values], dtype=torch.long).T\n",
    "test_edges = torch.tensor([[uid, friend_uid] for uid, friend_uid in test_df.values], dtype=torch.long).T\n",
    "\n",
    "\n",
    "graph_data = Data(edge_index=train_edges)\n",
    "graph_data = T.ToUndirected()(graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88ea2a-c706-44a0-b7a9-b371232a40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Node2Vec(\n",
    "    graph_data.edge_index,\n",
    "    embedding_dim=128,\n",
    "    walk_length=30,\n",
    "    context_size=10,\n",
    "    walks_per_node=10,\n",
    "    num_negative_samples=1,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    sparse=True,\n",
    ").to(device)\n",
    "\n",
    "# если пользовать num_workers > 1 выдает Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
    "# хз почему\n",
    "loader = model.loader(batch_size=512, shuffle=True, num_workers=1)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "508c5cf7-497e-42d9-a212-21b2cc550a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:46<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm \n",
    "\n",
    "def get_recommendations(user_embs: np.array, item_embs: np.array, k: int = 10, batch_size: int = 1024):\n",
    "    index = faiss.IndexFlatIP(item_embs.shape[1])\n",
    "    \n",
    "    faiss.normalize_L2(item_embs)\n",
    "    index.add(item_embs)\n",
    "    \n",
    "    all_distances = []\n",
    "    all_indices = []\n",
    "    \n",
    "    num_batches = (len(user_embs) + batch_size - 1) // batch_size\n",
    "    with tqdm(total=num_batches) as pbar:\n",
    "        for i in range(0, len(user_embs), batch_size):\n",
    "            batch_user_embs = user_embs[i:i + batch_size]\n",
    "            faiss.normalize_L2(batch_user_embs)\n",
    "            distances, indices = index.search(batch_user_embs, k)\n",
    "            all_distances.append(distances)\n",
    "            all_indices.append(indices)\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    all_distances = np.concatenate(all_distances, axis=0)\n",
    "    all_indices = np.concatenate(all_indices, axis=0)\n",
    "    \n",
    "    return all_indices, all_distances\n",
    "\n",
    "embeddings = model().cpu().detach().numpy()\n",
    "\n",
    "recommendations, distances = get_recommendations(embeddings, embeddings, k=60, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "69ec062e-2467-4ea5-a15a-5af5d68f4aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10 = 0.0740\n"
     ]
    }
   ],
   "source": [
    "test_true_friends = {user: set(test_df[test_df['uid'] == user]['friend_uid']) for user in test_df['uid'].unique()}\n",
    "\n",
    "user_to_friends = {}\n",
    "for uid, friend_uid in train_df.values:\n",
    "    if uid not in user_to_friends:\n",
    "        user_to_friends[uid] = set()\n",
    "    user_to_friends[uid].add(friend_uid)\n",
    "recall_scores = []\n",
    "\n",
    "TOP_K = 10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "SUBMISSION_PATH = 'submission.parquet'\n",
    "\n",
    "\n",
    "def user_intersection(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    :param y_rel: relevant items\n",
    "    :param y_rec: recommended items\n",
    "    :param k: number of top recommended items\n",
    "    :return: number of items in intersection of y_rel and y_rec (truncated to top-K)\n",
    "    \"\"\"\n",
    "    return len(set(y_rec[:k]).intersection(set(y_rel)))\n",
    "\n",
    "\n",
    "def user_recall(y_rel: List[Any], y_rec: List[Any], k: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    :param y_rel: relevant items\n",
    "    :param y_rec: recommended items\n",
    "    :param k: number of top recommended items\n",
    "    :return: percentage of found relevant items through recommendations\n",
    "    \"\"\"\n",
    "    return user_intersection(y_rel, y_rec, k) / min(k, len(set(y_rel)))\n",
    "\n",
    "for user_id in test_true_friends:\n",
    "    if user_id in user_to_friends:\n",
    "        y_true = list(test_true_friends[user_id])\n",
    "        \n",
    "        y_pred = [rec for rec in recommendations[user_id] if rec not in user_to_friends[user_id] and rec != user_id]\n",
    "        \n",
    "        recall_scores.append(user_recall(y_true, y_pred, k=20))\n",
    "\n",
    "mean_recall_at_10 = np.mean(recall_scores)\n",
    "print(f'Recall@10 = {mean_recall_at_10:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Сабмишн так делал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "\n",
    "train_df = pd.read_parquet('train.parquet')\n",
    "unique_users = pd.concat([train_df['uid'], train_df['friend_uid']]).unique()\n",
    "user_index = {user: idx for idx, user in enumerate(unique_users)}\n",
    "\n",
    "index_user = {idx: user for user, idx in user_index.items()}\n",
    "\n",
    "rows = train_df['uid'].map(user_index)\n",
    "cols = train_df['friend_uid'].map(user_index)\n",
    "data = np.ones(len(train_df), dtype=int)\n",
    "\n",
    "\n",
    "n_users = len(unique_users)\n",
    "sparse_matrix = csr_matrix((data, (rows, cols)), shape=(n_users, n_users))\n",
    "\n",
    "user_similarity = cosine_similarity(sparse_matrix, dense_output=False)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "user_to_friends = defaultdict(set)\n",
    "\n",
    "for uid, friend_uid in tqdm(zip(train_df['uid'], train_df['friend_uid']), total=len(train_df)):\n",
    "    user_to_friends[user_index[uid]].add(user_index[friend_uid])\n",
    "def generate_recommendations_sparse(user_similarity, user_to_friends, top_k=10):\n",
    "    recommendations = {}\n",
    "    for user in tqdm(range(user_similarity.shape[0]), total=user_similarity.shape[0]):\n",
    "        similarities = user_similarity[user].toarray().flatten()\n",
    "        friends = user_to_friends.get(user, set())\n",
    "        candidate_users = np.argpartition(-similarities, top_k)[:top_k]\n",
    "        candidate_users = candidate_users[np.argsort(-similarities[candidate_users])]\n",
    "        candidate_users = [uid for uid in candidate_users if uid != user and uid not in friends][:top_k]\n",
    "        recommendations[user] = candidate_users\n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_recommendations_sparse(user_similarity, user_to_friends, top_k=100)\n",
    "sample_submission = pl.read_parquet('sample_submission.parquet')\n",
    "\n",
    "submission = []\n",
    "for user_id in tqdm(sample_submission['uid'].to_list()):\n",
    "    user_idx = user_index[user_id]\n",
    "    y_rec = [index_user[rec] for rec in recommendations.get(user_idx, [])]\n",
    "    submission.append((user_id, y_rec))\n",
    "\n",
    "submission_df = pl.DataFrame(submission, schema=['user_id', 'y_recs'])\n",
    "\n",
    "submission_df.write_parquet('submission.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
